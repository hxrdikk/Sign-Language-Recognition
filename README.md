# âœ‹ Sign Language Recognition using CNN

This project implements an American Sign Language (ASL) recognition system using a **Convolutional Neural Network (CNN)**.  
It predicts hand gestures representing alphabets and supports real-time webcam recognition.

---

## ğŸ“‚ Dataset
- **Source:** [ASL Alphabet Dataset - Kaggle](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)  
- Contains **87,000+ images** of hand signs across **29 classes** (Aâ€“Z, SPACE, DELETE, NOTHING).  
- Images resized to **64Ã—64 RGB** before training.

---

## ğŸ§  Model
- **Architecture:** Custom CNN (Convolutional Neural Network)  
- **Input size:** 64 Ã— 64 Ã— 3  
- **Output classes:** 29 (Aâ€“Z + special tokens)  
- **Optimizer:** Adam  
- **Loss Function:** Categorical Crossentropy  

The trained model is saved as `SLR_final.h5`.  

âš ï¸ The model file is too large for GitHub (>100 MB).  
ğŸ‘‰ Download it here: [Google Drive Link](https://drive.google.com/drive/folders/1JjK75ni5MON4727yQDLzLVElz4cRE7QY?usp=sharing)

---

## ğŸ“Š Results

### âœ… Accuracy
- **Training Accuracy:** 98.86%  
- **Validation Accuracy:** 95.89%  
- **Test Accuracy (Augmented):** 95.29%  

### âœ… Confusion Matrix
The confusion matrix shows the modelâ€™s performance across different classes:

![Confusion Matrix](Results/Confusion%20Matrix.png)


---

## ğŸ¯ Sample Predictions

Here are some example outputs from the trained model:

| Sign | Prediction |
|------|------------|
| ![A](Results/A.png) | **A** |
| ![B](Results/B.png) | **B** |
| ![C](Results/C.png) | **C** |
| ![D](Results/D.png) | **D** |
| ![E](Results/E.png) | **E** |
| ![F](Results/F.png) | **F** |

---

## âš™ï¸ Installation & Usage

### 1. Clone the Repository
```bash
git clone https://github.com/hxrdikk/Sign-Language-Recognition.git
cd Sign-Language-Recognition
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Download Pretrained Model
Download `SLR_final.h5` from [Google Drive](https://drive.google.com/drive/folders/1JjK75ni5MON4727yQDLzLVElz4cRE7QY?usp=sharing)  
and place it in the **project root**.

### 4. Run Notebook
```bash
jupyter notebook SignLanguageRecognition.ipynb
```

### 5. Live Prediction via Webcam
```bash
python model_load.py
```

---

## ğŸ— Project Structure
```
Sign-Language-Recognition/
â”œâ”€â”€ Results/
â”‚   â”œâ”€â”€ A.png
â”‚   â”œâ”€â”€ B.png
â”‚   â”œâ”€â”€ C.png
â”‚   â”œâ”€â”€ D.png
â”‚   â”œâ”€â”€ E.png
â”‚   â”œâ”€â”€ F.png
â”‚   â””â”€â”€ Confusion_Matrix.png
â”œâ”€â”€ model_load.py
â”œâ”€â”€ test_Data_Split.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ SignLanguageRecognition.ipynb
â””â”€â”€ .gitignore
```

---

## ğŸ† Features
- ASL alphabet recognition (Aâ€“Z + SPACE, DELETE, NOTHING)  
- Custom CNN architecture  
- Confusion matrix + classification report  
- Real-time webcam prediction with OpenCV  
- Dataset splitting script (`test_Data_Split.py`)  

---

## ğŸ‘¨â€ğŸ’» Authors
- **Hardik Jain**  
---

## ğŸ“œ License
This project is open-source and available under the [MIT License](LICENSE).
