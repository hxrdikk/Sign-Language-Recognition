{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./dataset/asl_alphabet_train\"\n",
    "TEST_DIR = \"./dataset/asl_test_split\"\n",
    "\n",
    "IMG_SIZE   = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a228c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    validation_split=0.2   \n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "labels = {v:k for k,v in train_generator.class_indices.items()}\n",
    "print(\"Labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "  \n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    \n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    \n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "   \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"SLR_final.h5\")\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cb = [\n",
    "    callbacks.ModelCheckpoint(\"SLR_final.h5\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=25,\n",
    "    callbacks=cb\n",
    ")\n",
    "\n",
    "print(\"Training finished. Best model saved as SLR_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439206ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = \"./dataset/asl_test_split\"\n",
    "print(os.listdir(TEST_DIR)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e78e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.7, 1.3]\n",
    ")\n",
    "\n",
    "test_gen = test_aug.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "y_pred_probs = model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "class_labels = list(test_gen.class_indices.keys())\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=90, ax=ax)\n",
    "plt.title(\"Confusion Matrix - Augmented Test Set\")\n",
    "plt.show()\n",
    "\n",
    "acc = accuracy_score(test_gen.classes, y_pred)\n",
    "print(f\"Test Accuracy (Augmented): {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_history = deque(maxlen=10)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Starting webcam. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    x1, y1, x2, y2 = 100, 100, 300, 300\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    roi = cv2.resize(roi, (64, 64))\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = roi.astype(\"float32\")/255.0\n",
    "    roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "    pred = model.predict(roi, verbose=0)[0]\n",
    "    pred_history.append(pred)\n",
    "    avg_pred = np.mean(pred_history, axis=0)\n",
    "\n",
    "    class_id = np.argmax(avg_pred)\n",
    "    class_name = labels[class_id]\n",
    "    confidence = avg_pred[class_id] * 100\n",
    "\n",
    "    text = f\"{class_name}: {confidence:.2f}%\"\n",
    "    cv2.putText(frame, text, (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"ASL Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
